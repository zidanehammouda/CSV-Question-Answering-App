{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zidane/anaconda3/envs/proj_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TextGenerationPipeline\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv \n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/home/zidane/.cache/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.2/snapshots/41b61a33a2483885c981aa79e0df6b32407ed873\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "# model = AutoModelForCausalLM.from_pretrained(path)\n",
    "# device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:03<00:00,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "deepseek_model = {\n",
    "    \"tokenizer\": AutoTokenizer.from_pretrained(\"deepseek-ai/deepseek-coder-7b-instruct-v1.5\"),\n",
    "    \"model\" : AutoModelForCausalLM.from_pretrained(\"deepseek-ai/deepseek-coder-7b-instruct-v1.5\")\n",
    "}\n",
    "\n",
    "# mistral_model = {\n",
    "#     \"tokenizer\": AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\"),\n",
    "#     \"model\" : AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO ID                                                     REPO TYPE SIZE ON DISK NB FILES LAST_ACCESSED  LAST_MODIFIED REFS LOCAL PATH                                                                                      \n",
      "----------------------------------------------------------- --------- ------------ -------- -------------- ------------- ---- ----------------------------------------------------------------------------------------------- \n",
      "CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment           model           436.7M        5 3 weeks ago    3 weeks ago   main /disk/data/huggingface/hub/models--CAMeL-Lab--bert-base-arabic-camelbert-da-sentiment           \n",
      "MohamedGalal/marbert-sarcasm-detector                       model           655.2M        6 3 weeks ago    3 weeks ago   main /disk/data/huggingface/hub/models--MohamedGalal--marbert-sarcasm-detector                       \n",
      "deepseek-ai/deepseek-coder-33b-instruct                     model             9.7G        5 2 days ago     2 days ago    main /disk/data/huggingface/hub/models--deepseek-ai--deepseek-coder-33b-instruct                     \n",
      "deepseek-ai/deepseek-coder-7b-instruct-v1.5                 model            13.8G        8 21 minutes ago 2 days ago    main /disk/data/huggingface/hub/models--deepseek-ai--deepseek-coder-7b-instruct-v1.5                 \n",
      "hatemnoaman/bert-base-arabic-finetuned-emotion              model           443.7M        6 3 weeks ago    3 weeks ago   main /disk/data/huggingface/hub/models--hatemnoaman--bert-base-arabic-finetuned-emotion              \n",
      "liuhaotian/llava-v1.5-7b                                    model            13.5G        8 2 months ago   2 months ago  main /disk/data/huggingface/hub/models--liuhaotian--llava-v1.5-7b                                    \n",
      "liuhaotian/llava-v1.6-34b                                   model            69.5G       21 2 months ago   5 weeks ago   main /disk/data/huggingface/hub/models--liuhaotian--llava-v1.6-34b                                   \n",
      "liuhaotian/llava-v1.6-mistral-7b                            model            15.1G       11 2 months ago   2 months ago  main /disk/data/huggingface/hub/models--liuhaotian--llava-v1.6-mistral-7b                            \n",
      "liuhaotian/llava-v1.6-vicuna-7b                             model            14.1G        9 2 months ago   2 months ago  main /disk/data/huggingface/hub/models--liuhaotian--llava-v1.6-vicuna-7b                             \n",
      "llava-hf/llava-1.5-13b-hf                                   model            26.7G       15 2 months ago   2 months ago  main /disk/data/huggingface/hub/models--llava-hf--llava-1.5-13b-hf                                   \n",
      "llava-hf/llava-1.5-7b-hf                                    model            14.1G       12 2 months ago   5 weeks ago   main /disk/data/huggingface/hub/models--llava-hf--llava-1.5-7b-hf                                    \n",
      "llava-hf/vip-llava-13b-hf                                   model            26.7G       15 2 months ago   2 months ago  main /disk/data/huggingface/hub/models--llava-hf--vip-llava-13b-hf                                   \n",
      "mistralai/Mistral-7B-Instruct-v0.2                          model            14.5G       10 2 days ago     2 days ago    main /disk/data/huggingface/hub/models--mistralai--Mistral-7B-Instruct-v0.2                          \n",
      "openai/clip-vit-large-patch14-336                           model             1.7G        3 2 months ago   2 months ago  main /disk/data/huggingface/hub/models--openai--clip-vit-large-patch14-336                           \n",
      "sentence-transformers/all-distilroberta-v1                  model           659.6M       13 1 hour ago     2 weeks ago   main /disk/data/huggingface/hub/models--sentence-transformers--all-distilroberta-v1                  \n",
      "sentence-transformers/distiluse-base-multilingual-cased-v1  model             1.1G       15 2 weeks ago    2 weeks ago   main /disk/data/huggingface/hub/models--sentence-transformers--distiluse-base-multilingual-cased-v1  \n",
      "sentence-transformers/paraphrase-multilingual-mpnet-base-v2 model             1.1G       11 2 weeks ago    2 weeks ago   main /disk/data/huggingface/hub/models--sentence-transformers--paraphrase-multilingual-mpnet-base-v2 \n",
      "\n",
      "Done in 0.0s. Scanned 17 repo(s) for a total of \u001b[1m\u001b[31m224.0G\u001b[0m.\n",
      "\u001b[90mGot 12 warning(s) while scanning. Use -vvv to print details.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli scan-cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'Fare']\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived                                        0\n",
      "Pclass                                          3\n",
      "Name                       Mr. Owen Harris Braund\n",
      "Sex                                          male\n",
      "Age                                          22.0\n",
      "Siblings/Spouses Aboard                         1\n",
      "Parents/Children Aboard                         0\n",
      "Fare                                         7.25\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_response(text):\n",
    "    pattern = r\"```python(.*?)```\"\n",
    "    matches = re.findall(pattern, text, re.DOTALL)\n",
    "    if matches:\n",
    "        return {'response_error':False,'response':matches[0]}\n",
    "    else:\n",
    "        return {'response_error':True,'response':text}\n",
    "\n",
    "def generate_response(prompt,model_name):\n",
    "    try:\n",
    "        coder_model_prompt = [\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        encodeds = model_name[\"tokenizer\"].apply_chat_template(coder_model_prompt, return_tensors=\"pt\")\n",
    "\n",
    "        model_inputs = encodeds.to(device)\n",
    "        model_name['model'].to(device)\n",
    "\n",
    "        generated_ids = model_name['model'].generate(model_inputs, max_new_tokens=500, do_sample=False,temperature=0.1,repetition_penalty=1)\n",
    "        decoded = model_name[\"tokenizer\"].batch_decode(generated_ids)\n",
    "        return decoded[0].split('[/INST]')[-1].split('</s>')[0]\n",
    "    except:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"df is a dataframe that {description}. df has these columns: {columns}. Write python code that answers this question: Print {question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_description = 'containing the list of people that were on the titanic ship and some details such as age, sex, name and whether they survived or not'\n",
    "titanic_columns = '''['Survived', 'Pclass', 'Name', 'Sex', 'Age', 'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'Fare']'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. What is the fare for Mr. Owen Harris Braund?\n",
    "answer1 = df[df['Name'] == \"Mr. Owen Harris Braund\"]['Fare'].iloc[0]\n",
    "\n",
    "# 2. How many females are in the dataset?\n",
    "answer2 = df[df['Sex'] == \"female\"].shape[0]\n",
    "\n",
    "# 3. What is the average age of the passengers?\n",
    "answer3 = df['Age'].mean()\n",
    "\n",
    "# 4. How many passengers survived?\n",
    "answer4 = df[df['Survived'] == 1].shape[0]\n",
    "\n",
    "# 5. Who paid the highest fare?\n",
    "answer5 = df.loc[df['Fare'].idxmax(), 'Name']\n",
    "\n",
    "# 6. What is the total amount of fare paid?\n",
    "answer6 = df['Fare'].sum()\n",
    "\n",
    "# 7. Who is the passenger that has the highest number of siblings abroad?\n",
    "answer7 = df.loc[df['Siblings/Spouses Aboard'].idxmax(), 'Name']\n",
    "\n",
    "# 8. What is the age of Miss. Laina Heikkinen?\n",
    "answer8 = df[df['Name'] == \"Miss. Laina Heikkinen\"]['Age'].iloc[0]\n",
    "\n",
    "# 9. How many passengers are in the 1st class?\n",
    "answer9 = df[df['Pclass'] == 1].shape[0]\n",
    "\n",
    "# 10. What is the average fare paid by passengers?\n",
    "answer10 = df['Fare'].mean()\n",
    "\n",
    "# 11. How many passengers have 0 siblings/spouses aboard?\n",
    "answer11 = df[df['Siblings/Spouses Aboard'] == 0].shape[0]\n",
    "\n",
    "# 12. Who is the oldest passenger in the dataset?\n",
    "answer12 = df.loc[df['Age'].idxmax(), 'Name']\n",
    "\n",
    "# 13. How many passengers did not survive?\n",
    "answer13 = df[df['Survived'] == 0].shape[0]\n",
    "\n",
    "# 14. What is the lowest fare paid in the dataset?\n",
    "answer14 = df['Fare'].min()\n",
    "\n",
    "test_cases_titanic = [\n",
    "    {'question': 'What is the fare for Mr. Owen Harris Braund?', 'answer': answer1},\n",
    "    {'question': 'How many females are in the dataset?', 'answer': answer2},\n",
    "    {'question': 'What is the average age of the passengers?', 'answer': answer3},\n",
    "    {'question': 'How many passengers survived?', 'answer': answer4},\n",
    "    {'question': 'Who paid the highest fare?', 'answer': answer5},\n",
    "    {'question': 'What is the total amount of fare paid?', 'answer': answer6},\n",
    "    {'question': 'Who is the passanger that has the highest number of siblings abroad ?', 'answer': answer7},\n",
    "    {\"question\": \"What is the age of Miss. Laina Heikkinen?\", \"answer\": answer8},\n",
    "    {\"question\": \"How many passengers are in the 1st class?\", \"answer\": answer9},\n",
    "    {\"question\": \"What is the average fare paid by passengers?\", \"answer\": answer10},\n",
    "    {\"question\": \"How many passengers have 0 siblings/spouses aboard?\", \"answer\": answer11},\n",
    "    {\"question\": \"Who is the oldest passenger in the dataset?\", \"answer\": answer12},\n",
    "    {\"question\": \"How many passengers did not survive?\", \"answer\": answer13},\n",
    "    {\"question\": \"What is the lowest fare paid in the dataset?\", \"answer\": answer14}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. What is the monthly income of the first female in the dataset?\n",
    "answer1 = df.loc[df['Gender'] == \"Female\", 'Monthly Income'].iloc[0]\n",
    "\n",
    "# 2. How many students are there in the dataset?\n",
    "answer2 = (df['Occupation'] == \"Student\").sum()\n",
    "\n",
    "# 3. What is the average age of participants?\n",
    "answer3 = df['Age'].mean()\n",
    "\n",
    "# 4. How many participants provided positive feedback?\n",
    "answer4 = (df['Feedback'] == \"Positive\").sum()\n",
    "\n",
    "# 5. What is the educational qualification of the male participant?\n",
    "answer5 = df.loc[df['Gender'] == \"Male\", 'Educational Qualifications'].iloc[0]\n",
    "\n",
    "# 6. How many participants are single?\n",
    "answer6 = (df['Marital Status'] == \"Single\").sum()\n",
    "\n",
    "# 7. What is the most common marital status in the dataset?\n",
    "answer7 = df['Marital Status'].mode()[0]\n",
    "\n",
    "# 8. Are there any participants with a family size greater than 3?\n",
    "answer8 = \"Yes\" if any(df['Family size'] > 3) else \"No\"\n",
    "\n",
    "# 9. What is the pin code for the location with the highest latitude?\n",
    "answer9 = df.loc[df['latitude'].idxmax(), 'Pin code']\n",
    "\n",
    "# 10. Did any participant with negative feedback have a monthly income below Rs.10000?\n",
    "answer10 = \"Yes\" if any((df['Feedback'] == \"Negative\") & (df['Monthly Income'] == \"Below Rs.10000\")) else \"No\"\n",
    "\n",
    "test_cases_food=[\n",
    "    {\"question\": \"What is the monthly income of the first female in the dataset?\", \"answer\": answer1},\n",
    "    {\"question\": \"How many students are there in the dataset?\", \"answer\": answer2},\n",
    "    {\"question\": \"What is the average age of participants?\", \"answer\": answer3},\n",
    "    {\"question\": \"How many participants provided positive feedback?\", \"answer\": answer4},\n",
    "    {\"question\": \"What is the educational qualification of the male participant?\", \"answer\": answer5},\n",
    "    {\"question\": \"How many participants are single?\", \"answer\": answer6},\n",
    "    {\"question\": \"What is the most common marital status in the dataset?\", \"answer\": answer7},\n",
    "    {\"question\": \"Are there any participants with a family size greater than 3?\", \"answer\": answer8},\n",
    "    {\"question\": \"What is the pin code for the location with the highest latitude?\", \"answer\": answer9},\n",
    "    {\"question\": \"Did any participant with negative feedback have a monthly income below Rs.10000?\", \"answer\": answer10}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import sys\n",
    "def get_print(code):\n",
    "    buffer = io.StringIO()\n",
    "    sys.stdout = buffer\n",
    "\n",
    "    exec(code)\n",
    "\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "    return buffer.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_description = 'The dataset contains information collected from an online food ordering platform over a period of time.'\n",
    "food_columns = \"['Age', 'Gender', 'Marital Status', 'Occupation', 'Monthly Income', 'Educational Qualifications', 'Family size', 'latitude', 'longitude', 'Pin code', 'Output', 'Feedback', 'Unnamed: 12']\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []  \n",
    "from tqdm import tqdm\n",
    "for tc in tqdm(test_cases_food):\n",
    "    prompt = prompt_template.format(description=food_description,columns=food_columns,question=tc['question'])\n",
    "    full_response = generate_response(prompt,deepseek_model)\n",
    "    extracted_code = extract_response(full_response)\n",
    "    try:\n",
    "        execution = get_print(extracted_code['response'])\n",
    "    except:\n",
    "        execution = 'Execution error'\n",
    "    data.append({\n",
    "        'question': tc['question'],\n",
    "        'answer': tc['answer'],\n",
    "        'response_error': extracted_code.get('response_error', None),  # Use .get to avoid KeyError if 'error' is missing\n",
    "        'response': extracted_code.get('response', None),\n",
    "        'execution': execution\n",
    "    })\n",
    "\n",
    "# Once the loop is complete, convert the list of dictionaries into a DataFrame\n",
    "testdf = pd.DataFrame(data)\n",
    "testdf.to_excel('food_results.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Height(Inches)\"</th>\n",
       "      <th>\"Weight(Pounds)\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>65.78</td>\n",
       "      <td>112.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>71.52</td>\n",
       "      <td>136.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>69.40</td>\n",
       "      <td>153.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>68.22</td>\n",
       "      <td>142.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>67.79</td>\n",
       "      <td>144.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index   Height(Inches)\"   \"Weight(Pounds)\"\n",
       "0      1             65.78             112.99\n",
       "1      2             71.52             136.49\n",
       "2      3             69.40             153.03\n",
       "3      4             68.22             142.34\n",
       "4      5             67.79             144.30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Index', ' Height(Inches)\"', ' \"Weight(Pounds)\"'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138    139\n",
      "Name: Index, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('hw_200.csv')\n",
    "# Assuming df is your DataFrame\n",
    "highest_person_index = df['Index'][df[' Height(Inches)\"'] == df[' Height(Inches)\"'].max()]\n",
    "print(highest_person_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
